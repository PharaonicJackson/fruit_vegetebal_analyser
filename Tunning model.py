import os
import fonction_modele_keras
import fonctions_utiles
from function_dataset import get_data
from tensorflow import keras
from sklearn.model_selection import KFold, cross_val_score, train_test_split
import math
import shutil
import numpy as np

os.environ[
    "KMP_DUPLICATE_LIB_OK"] = "TRUE"  # pour resoudre ce message d'erreur OMP: Error #15: Initializing libiomp5, but found libiomp5md.dll already initialized.


def create_repository():

    '''
    Cree les different repository pur stocker les fichiers log des differents callbacks
    :return:
    '''

    # Creation si n'existe pas du folder callback
    folder = [f for f in os.listdir(os.getcwd()) if
              not os.path.isfile(os.path.join(os.getcwd(), f))]  # Liste les repository
    if 'callback' in folder:
        pass
        # shutil.rmtree(os.path.join(os.getcwd(),'callback')) # supprime repertoire
    else:
        os.mkdir('callback')

    if 'best_model' not in folder: # Endroit ou sont enregistre et charge les meilleurs modeles
        os.mkdir('best_model')
    folder = [f for f in os.listdir(os.path.join(os.getcwd(), 'best_model'))
              if not os.path.isfile(os.path.join(os.getcwd(), f))]  # Liste les repository
    if 'history_best_model' not in folder: # Verifie que le dossier history_best_model existe
        os.mkdir('best_model/history_best_model')



    # Creation du sous dossier cross_val vide (pour validation croisee)
    folder = [f for f in os.listdir(os.path.join(os.getcwd(), 'callback'))
              if not os.path.isfile(os.path.join(os.getcwd(), f))]  # Liste les repository
    if 'cross_val' in folder: # Si le dossier cros_val existe, je supprime tout les fichiers a l'interieur
        [os.remove(os.path.join(os.getcwd(), 'callback','cross_val', f))
         for f in os.listdir(os.path.join(os.getcwd(), 'callback','cross_val'))]
    else:
        os.mkdir('./callback/cross_val') # Si le dossier n'existe pas je le cree

    if 'log' in folder: # Si le dossier log existe, je supprime tout les fichiers a l'interieur
        [shutil.rmtree(os.path.join(os.getcwd(), 'callback', 'log', f))
         for f in os.listdir(os.path.join(os.getcwd(), 'callback', 'log'))]
    else:
        os.mkdir('./callback/log') # Si le dossier n'existe pas je le cree

def create_name_and_folder_tunning_modele(fold_var):
    '''
    Creer les differents dossier pour ranger les callbachs si necessaire ainsi que les chemins des differents callbacks

    :param dict_label: Dictionnaire des labels de et entrainement

    :return: fold_var : cnumero de split de la validation croisee
    '''

    # Creation des nom des chemins pour les differents callbacks path_fichier_callback_Checkpoint1 =
    # fonctions_utiles.unique_time_filename(dir='./callback', prefix='cb_checkpoint_wei_', suffix='.log')
    path_fichier_callback_Checkpoint2 = fonctions_utiles.get_model_path(abs_dir='./callback/cross_val', k=fold_var)
    path_callback_tensorboard = fonctions_utiles.unique_path_time_filename(dir='./callback/log', prefix='cb_tensorboard_', suffix='_split_' + str(fold_var))

    return path_fichier_callback_Checkpoint2, path_callback_tensorboard


def tunning_model(dataset_path: str, learning_rate: int, epochs:int, earlystop_patience: int, batch_size: int, pourc_dataset: int):
    '''
    Realise un apprentissage avec validation croisee.
    Savegarde le meilleur modele dans ./best_modele/best_modele.h5.
    Possibilite de suivre l'evolutioon sur tensor board


    :param dataset_path: Chemin absolu du dataset avec un dossier train et un dossier test
    :param learning_rate: taux d'apprentissage du modele
    :param epochs:M=Nombre d'epoch
    :param earlystop_patience: patience de l'early stopping
    :param batch_size: taille du batch.
    :param nbr_split: nbr de split de la validation croisee.
    :param pourc_dataset: Pourcentade du dataset utilise pour entrainer le model.
    :return:
    '''

    # VALIDATION_ACCURACY = []
    # VALIDAITON_LOSS = []
    fold_var = 1
    dataset_path = os.path.join(dataset_path)

    create_repository()

    # Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds 
    # kf = KFold(nbr_split, shuffle=True)  # Creation de 5 splits

    # Chargement des donnees
    x_train_tot, _, y_train_tot, _ = get_data(dataset_dir=dataset_path, pourc_dataset=pourc_dataset)

    keras.backend.clear_session()  # Resets all state generated by Keras.

    # Separation des donnees train et validation (0.8/0.2)
    nbr_data = len(x_train_tot)
    x_train = x_train_tot[0:math.ceil(0.8*nbr_data)]
    y_train = y_train_tot[0:math.ceil(0.8*nbr_data)]
    x_val = x_train_tot[math.ceil(0.8*nbr_data):]
    y_val = y_train_tot[math.ceil(0.8*nbr_data):]

    # Partition des donnees selon le facteur demande
    # Donnees d'entrainement
    nbr_data = len(x_train)
    x_train = x_train[0:math.ceil(pourc_dataset * nbr_data)]
    y_train = y_train[0:math.ceil(pourc_dataset * nbr_data)]
    # Donnees de validation
    nbr_data = len(x_val)
    x_val = x_val[0:math.ceil(pourc_dataset * nbr_data)]
    y_val = y_val[0:math.ceil(pourc_dataset * nbr_data)]


    (lx, ly, lz) = x_train[0].shape  # Modele en nb

    my_model = fonction_modele_keras.create_model_AlexNet2(lx, ly, lz)


    my_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
                     loss='categorical_crossentropy',
                     metrics='accuracy')

    # Creation du callback pour enregistrer les differents resultats.
    # Call back qui mesure val_accuracy et accuracy
    # Creation des differents noms.
    path_fichier_callback_Checkpoint2, path_callback_tensor_board = create_name_and_folder_tunning_modele(
        fold_var=fold_var)

    callback_earlystopping = keras.callbacks.EarlyStopping(
        monitor='val_accuracy',
        min_delta=0,
        patience=earlystop_patience)

    callback_tensorboard = keras.callbacks.TensorBoard(log_dir=path_callback_tensor_board)

    # Check point pour la validation croisee
    callback_checkpoint2 = keras.callbacks.ModelCheckpoint(path_fichier_callback_Checkpoint2,
                                                           monitor='val_accuracy', verbose=1,
                                                           save_best_only=True, mode='auto')

    # Chargement des poids du meilleur modele si existant sinon garde poids aleatoire
    my_model.load_weights(os.path.join(os.getcwd(),'best_model','best_weight_save.h5'))

    my_model.fit(x_train, y_train,
                 batch_size=batch_size,
                 epochs=epochs,
                 verbose=True,
                 callbacks=[callback_checkpoint2, callback_earlystopping, callback_tensorboard],
                 validation_data=(x_val, y_val))


    # Enregistrement du meilleur modele
    my_model.save_weights(os.path.join(os.getcwd(), 'best_model', 'best_weight_save.h5'),save_format='h5')
    my_model.save(os.path.join(os.getcwd(), 'best_model', 'best_model_save.h5'),save_format='h5')



if __name__ == '__main__':

    #  # rate = [0.01, 0.0008, 0.005, 0.001, 0.0008, 0.,0005, 0.0001]
    # for each_rate in rate:
    # 0.0008 print('new_rate: ', each_rate)
    tunning_model(dataset_path='./corn_227_227_RGB_from_kaggle',
                  learning_rate=0.000001,
                  batch_size=8,
                  earlystop_patience=3,
                  epochs=50,
                  pourc_dataset=1)
